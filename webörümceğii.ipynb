{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4YQg1a//p/n9rp+mtu4cJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enesordek/hu-bby162-2024/blob/main/web%C3%B6r%C3%BCmce%C4%9Fii.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1itN4rH9T6D",
        "outputId": "14165476-02ca-4f7d-9b5d-9e4c60b2b709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ziyaret edilen: https://www.adidas.com.tr/tr\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Kullanıcıdan başlangıç URL'si ve derinlik bilgisi al\n",
        "#@title Web Örümceği Başlangıç Ayarları\n",
        "start_url = \"https://www.adidas.com.tr/tr\"  #@param {type:\"string\"}\n",
        "depth = 2  #@param {type:\"number\"}\n",
        "\n",
        "# Bağlantıları almak için bir fonksiyon\n",
        "def get_links(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        links = []\n",
        "        for link in soup.find_all('a', href=True):\n",
        "            links.append(link['href'])\n",
        "        return links\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {url}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Web örümceğinin tarama işlemini gerçekleştirecek fonksiyon\n",
        "def crawl(url, depth, visited, output_file):\n",
        "    if depth == 0:\n",
        "        return\n",
        "\n",
        "    # Ziyaret edilen URL'yi kaydetme\n",
        "    if url not in visited:\n",
        "        visited.add(url)\n",
        "        print(f\"Ziyaret edilen: {url}\")\n",
        "\n",
        "        # Sayfanın başlığını al\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            title = soup.title.string if soup.title else 'Başlık Bulunamadı'\n",
        "            print(f\"Başlık: {title}\")\n",
        "\n",
        "            # Sayfa bilgilerini dosyaya kaydet\n",
        "            with open(output_file, \"a\") as f:\n",
        "                f.write(f\"URL: {url}\\nBaşlık: {title}\\n\\n\")\n",
        "\n",
        "            # Bağlantıları al ve ziyaret et\n",
        "            links = get_links(url)\n",
        "            for link in links:\n",
        "                if not link.startswith('http'):  # Bağlantıyı tam adres yapma\n",
        "                    link = url + link\n",
        "                crawl(link, depth-1, visited, output_file)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error visiting {url}: {e}\")\n",
        "\n",
        "# Taramayı başlat\n",
        "visited_urls = set()\n",
        "output_file = \"visited_pages.txt\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    f.write(\"Tarama Sonuçları:\\n\\n\")\n",
        "\n",
        "# Web örümceğini çalıştır\n",
        "crawl(start_url, depth, visited_urls, output_file)\n",
        "\n",
        "print(f\"Tarama işlemi tamamlandı. Sonuçlar {output_file} dosyasına kaydedildi.\")\n"
      ]
    }
  ]
}